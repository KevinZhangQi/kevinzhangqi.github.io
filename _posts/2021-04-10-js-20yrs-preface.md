---
layout:       post
title:        "AI的“陪伴式交互”"
author:       "Kevin"
header-style: text
catalog:      true
tags:
    - AI
    - 产品设计
    - 交互
    - 瞎扯
---

> 上次创业做“陪伴式服务”的时候，我们的后台坐席上，是一个个鲜活的人，虽然成本高，但是人工的优势在于灵活性，机动性，遇到不会的可以现学现卖，以及，人工在遇到解决不了的问题的时候，可以卖萌。现在，AI正在快速抹平这些差异，甚至正在做的更好。

随着ChatGPT以及各种多模态大模型的出现，“AI能干什么？”这个问题的答案一直在被扩展。单从信息层面，暂时不讨论质量或者精准度，今天的AI模型，可以主动收集信息，处理信息，理解信息以及根据信息的含义，决定下一步的动作。在多模态的加持下，无论是对AI的输入还是AI的输出，在形式上都非常灵活，在轻交互的场景下（比如微信聊天框）也许是文字，如果界面更丰富一些（比如抖音，Facebook），那么也许可以是图片或者视频，如果进一步在一个沉浸式虚拟的平台下（比如Quest或者Vision Pro），可以生成并控制一个3D模型。

在这样的能力的加持下，似乎可以把AI近似看做成一个具有丰富能力的人了。那么和AI交互的问题，其实变成了“我和这个人怎么交互？”以及“这个人怎么和我交互？”这样，就把AI的交互方式和场景拓展开了。

如果有这样一个“人”，首先我会需要我可以和这个AI方便的进行自然语言的对话，在我上班的路上，在我游戏的对局里，在做饭的过程中，甚至是在我看剧的时候可以和他讨论剧情。然后，我可以发微信或是邮件给他，让他做一些我不必马上处理的事情，比如收集信息，整理信息等。
这种场景下，信息的交换发生在了很多不同的载体上，但是背后交互的AI应该是同一个，所以这里的AI更像是一个可以被不同工具植入或者是可以外挂在不同的输入输出设备上的能力。面对不同的工具或者不同的设备，输入和输出的能力与形态都会有一定的限制，但好在这种限制是比较自然且可扩展的，我们不可能要求对着一个智能手环要求他输出大屏幕的体验，当我们对着手机进行语音交互的时候，我们也会希望AI可以充分利用手机的屏幕，扬声器和各种传感器。
同样是因为多模态的能力与设备特性的限制，与AI交互的场景下，输入和输出便不一定是空间连续或者时间连续的。比如通过手环告诉AI让他在家里的电视输出，或者通过AI告诉我的智能汽车，让他在未来连续几天不下雨的时候，提醒我去洗车。

AI基础设施/基础能力，和电一样。电力公司不必担心用户关掉了任何一盏灯，因为总有其他的电器在为用户提供服务。

我们如果继续类比这样的一个“人”，在交互形式上的丰富之外，信息的流向也可以是双向的，AI可以主动发起上下文。这里的主动，是指除了用户自己设定的提醒之外的（比如新邮件，会议提醒，航班提醒）基于对用户所处场景的理解的会话。比如“最近中东冲突很严重，要不要帮你关注下石油价格走势？”，“现在小朋友坐高铁要实名制了，记得带户口本”，“这一季的流行色是粉色，要不要试试？”。这样的体验和推送广告会有很大区别，因为AI提供的是一个自然的交互上下文，而非每次都是带到一个商详页或者活动落地页上。而且由于AI被当做一个人来看待，又可以在后续的流程上和基于对用户反馈的理解针对性的提供服务，这类交互是可以做的比单纯的推送广告要体验好的多。

这样，这种陪伴式的AI其实成为了一个超级入口，一方面可以承接用户的多种需求，一方面自己也会创造需求给用户。而且用户对于一个拟人的角色，会有天然的信任感，这种信任会使整个交互流程更高效。AI的这种能力可以影响甚至垄断用户的信息摄入和认知形成，这里不止有商业机会也有道德风险。

互联网刚开始的时候，互联网主要承载的是信息，各种丰富的信息散落在各个网站上，需要一个信息集中检索和分发的机制，Yahoo和Google扮演了这个角色。后来，互联网上出现了商品，对应的商品检索和分发的工具是eBay和Amazon这类电商服务。现在各种不同领域的多模态大模型可以满足用户不同的需求，有无数的我们所不知道的AI能力等待被发现和被使用，类似AutoGPT，AutoGen这样的框架也在逐步的朝这个方向努力，期待能尽快看到下一代的AI交互形式。

— 张琦，互联网，移动互联网，智能硬件，AI啥都做一点，略懂。
